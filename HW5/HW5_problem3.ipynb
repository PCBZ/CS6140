{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PCBZ/CS6140/blob/main/HW5/HW5_problem3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1suaV0tdOLGU",
        "outputId": "d929f29a-9e57-43f3-e932-c7b8ffd4872b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.7.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "==================================================\n",
            "Spambase Evaluation\n",
            "==================================================\n",
            "k=1: Train Accuracy=99.97%, Test Accuracy=92.07%\n",
            "k=3: Train Accuracy=95.24%, Test Accuracy=90.23%\n",
            "k=7: Train Accuracy=92.66%, Test Accuracy=90.23%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Progress: 100%|██████████| 60/60 [04:04<00:00,  4.08s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:39<00:00,  3.98s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [02:33<00:00,  2.57s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:25<00:00,  2.53s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [04:26<00:00,  4.45s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:44<00:00,  4.41s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [03:58<00:00,  3.97s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:39<00:00,  3.95s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [02:31<00:00,  2.53s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:25<00:00,  2.52s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [04:26<00:00,  4.44s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:43<00:00,  4.35s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [03:57<00:00,  3.96s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:39<00:00,  3.91s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [02:31<00:00,  2.53s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:25<00:00,  2.52s/it, Batch 10/10 (1000 samples)]\n",
            "Progress: 100%|██████████| 60/60 [04:25<00:00,  4.42s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:44<00:00,  4.46s/it, Batch 10/10 (1000 samples)]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Digit Evaluation\n",
            "==================================================\n",
            "k=1, metric=cosine: Train Accuracy=100.00%, Test Accuracy=94.59%\n",
            "k=1, metric=rbf: Train Accuracy=100.00%, Test Accuracy=94.57%\n",
            "k=1, metric=poly: Train Accuracy=58.83%, Test Accuracy=58.01%\n",
            "k=3, metric=cosine: Train Accuracy=97.59%, Test Accuracy=94.86%\n",
            "k=3, metric=rbf: Train Accuracy=97.73%, Test Accuracy=95.10%\n",
            "k=3, metric=poly: Train Accuracy=61.69%, Test Accuracy=61.31%\n",
            "k=7, metric=cosine: Train Accuracy=96.07%, Test Accuracy=94.78%\n",
            "k=7, metric=rbf: Train Accuracy=96.29%, Test Accuracy=94.91%\n",
            "k=7, metric=poly: Train Accuracy=62.54%, Test Accuracy=61.61%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%pip install ucimlrepo\n",
        "\n",
        "from sklearn.metrics.pairwise import pairwise_distances, rbf_kernel, polynomial_kernel\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "class KNNClassifier:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _calculate_distances(self, X):\n",
        "        if self.distance_metric == 'euclidean' or self.distance_metric == 'cosine':\n",
        "            distances = pairwise_distances(X, self.X_train, metric=self.distance_metric)\n",
        "        elif self.distance_metric == 'rbf':\n",
        "            gamma = 1.0 / self.X_train.shape[1]\n",
        "            similarities = rbf_kernel(X, self.X_train, gamma=gamma)\n",
        "            distances = np.sqrt(2*(1 - similarities))\n",
        "        elif self.distance_metric == 'poly':\n",
        "            similarities = polynomial_kernel(X, self.X_train, degree=2)\n",
        "            similarities = (similarities - similarities.min()) / (similarities.max() - similarities.min() + 1e-8)\n",
        "            distances = np.sqrt(2*(1 - similarities))\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid distance metric: {self.distance_metric}\")\n",
        "        return distances\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        all_test_distances = self._calculate_distances(X)\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            test_distances = all_test_distances[i]\n",
        "\n",
        "            k_nearest_indices = np.argsort(test_distances)[:self.k]\n",
        "            k_nearest_labels = self.y_train[k_nearest_indices]\n",
        "\n",
        "            vote_counts = Counter(k_nearest_labels)\n",
        "            predicted_label = vote_counts.most_common(1)[0][0]\n",
        "            predictions.append(predicted_label)\n",
        "\n",
        "        return np.array(predictions)\n",
        "\n",
        "class BatchKNNClassifier(KNNClassifier):\n",
        "    \"\"\"\n",
        "    KNN Classifier with batch processing.\n",
        "    \"\"\"\n",
        "    def __init__(self, k=3, distance_metric='euclidean', batch_size=1000):\n",
        "        super().__init__(k, distance_metric)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def _calculate_distances(self, X):\n",
        "        if self.distance_metric == 'euclidean' or self.distance_metric == 'cosine':\n",
        "            distances = pairwise_distances(X, self.X_train, metric=self.distance_metric)\n",
        "        elif self.distance_metric == 'rbf':\n",
        "            gamma = 1.0 / self.X_train.shape[1]\n",
        "            similarities = rbf_kernel(X, self.X_train, gamma=gamma)\n",
        "            distances = np.sqrt(2*(1 - similarities))\n",
        "        elif self.distance_metric == 'poly':\n",
        "            similarities = polynomial_kernel(X, self.X_train, degree=2)\n",
        "            similarities = (similarities - similarities.min()) / (similarities.max() - similarities.min() + 1e-8)\n",
        "            distances = np.sqrt(2*(1 - similarities))\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid distance metric: {self.distance_metric}\")\n",
        "        return distances\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict labels for a batch of samples.\n",
        "        \"\"\"\n",
        "        X = np.array(X)\n",
        "        all_predictions = []\n",
        "\n",
        "        # The number of batches\n",
        "        n_batches = (len(X) + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "        batch_progress = tqdm(total=n_batches, desc=\"Progress\", position=0)\n",
        "\n",
        "        for batch_idx in range(n_batches):\n",
        "            # Get current batch data\n",
        "            start_idx, end_idx = batch_idx * self.batch_size, min((batch_idx + 1) * self.batch_size, len(X))\n",
        "            X_batch = X[start_idx:end_idx]\n",
        "\n",
        "            batch_progress.set_postfix_str(f\"Batch {batch_idx+1}/{n_batches} ({len(X_batch)} samples)\")\n",
        "\n",
        "            # Batch distance calculation\n",
        "            batch_distances = self._calculate_distances(X_batch)\n",
        "\n",
        "            batch_predictions = []\n",
        "\n",
        "            # Predict for each sample in the batch\n",
        "            for i in range(len(X_batch)):\n",
        "                test_distances = batch_distances[i]\n",
        "                k_nearest_indices = np.argsort(test_distances)[:self.k]\n",
        "                k_nearest_labels = self.y_train[k_nearest_indices]\n",
        "\n",
        "                vote_counts = Counter(k_nearest_labels)\n",
        "                predicted_label = vote_counts.most_common(1)[0][0]\n",
        "                batch_predictions.append(predicted_label)\n",
        "\n",
        "            # Add batch prediction results\n",
        "            all_predictions.extend(batch_predictions)\n",
        "\n",
        "            # Memory cleanup\n",
        "            del batch_distances, batch_predictions\n",
        "            gc.collect()\n",
        "\n",
        "            batch_progress.update(1)\n",
        "\n",
        "        batch_progress.close()\n",
        "\n",
        "        return np.array(all_predictions)\n",
        "\n",
        "\n",
        "def fetch_spambase_data():\n",
        "    \"\"\"\n",
        "    Fetch Spambase dataset from UCI repository\n",
        "    \"\"\"\n",
        "    spambase = fetch_ucirepo(id=94)\n",
        "\n",
        "    # Extract features and targets\n",
        "    X = spambase.data.features.values\n",
        "    y = spambase.data.targets.values.ravel()\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_data(X, y):\n",
        "    \"\"\"\n",
        "    Preprocess the data\n",
        "    \"\"\"\n",
        "    # Covert labels to 1/-1\n",
        "    y = np.where(y == 0, -1, 1)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def fetch_digit_dataset():\n",
        "    zip_url = \"https://www.khoury.northeastern.edu/home/vip/teach/MLcourse/data/mnist_haar_bingyu.zip\"\n",
        "    zip_filename = \"mnist_haar_bingyu.zip\"\n",
        "    extracted_folder = \"mnist_haar_bingyu\"\n",
        "    response = requests.get(zip_url)\n",
        "    with open(zip_filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "\n",
        "    train_images = np.loadtxt(os.path.join(extracted_folder, \"training_image.txt\"), delimiter=',')\n",
        "    train_labels = np.loadtxt(os.path.join(extracted_folder, \"training_label.txt\"), dtype=int, delimiter=',')\n",
        "    test_images = np.loadtxt(os.path.join(extracted_folder, \"testing_image.txt\"), delimiter=',')\n",
        "    test_labels = np.loadtxt(os.path.join(extracted_folder, \"testing_label.txt\"), dtype=int, delimiter=',')\n",
        "\n",
        "    return train_images, test_images, train_labels, test_labels\n",
        "\n",
        "def train_and_evaluate_spambase(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate the model on Spambase dataset\n",
        "    \"\"\"\n",
        "    print(\"=\"*50)\n",
        "    print(\"Spambase Evaluation\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for k in [1, 3, 7]:\n",
        "        model = KNNClassifier(k=k, distance_metric='euclidean')\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "        print(f\"k={k}: Train Accuracy={train_accuracy:.2%}, Test Accuracy={test_accuracy:.2%}\")\n",
        "\n",
        "def train_and_evaluate_digit(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate the model on Digit dataset\n",
        "    \"\"\"\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for k in [1, 3, 7]:\n",
        "        for metric in ['cosine', 'rbf', 'poly']:\n",
        "            model = BatchKNNClassifier(k=k, distance_metric=metric)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            y_train_pred = model.predict(X_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "\n",
        "            train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "            results[f\"k={k}, metric={metric}\"] = (train_accuracy, test_accuracy)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Digit Evaluation\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for result, (train_acc, test_acc) in results.items():\n",
        "        print(f\"{result}: Train Accuracy={train_acc:.2%}, Test Accuracy={test_acc:.2%}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Spambase\n",
        "    X, y = fetch_spambase_data()\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
        "\n",
        "    train_and_evaluate_spambase(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # Digit\n",
        "    X_train, X_test, y_train, y_test = fetch_digit_dataset()\n",
        "\n",
        "    train_and_evaluate_digit(X_train, X_test, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ucimlrepo\n",
        "\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import gc\n",
        "\n",
        "\n",
        "class FixedWindowKNNClassifier:\n",
        "    \"\"\"\n",
        "    Fixed Window KNN Classifier\n",
        "    \"\"\"\n",
        "    def __init__(self, radius=1.0, distance_metric='euclidean'):\n",
        "        self.radius = radius\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def _calculate_distances(self, X):\n",
        "        return pairwise_distances(X, self.X_train, metric=self.distance_metric)\n",
        "\n",
        "    def predict(self, X):\n",
        "        all_predictions = []\n",
        "\n",
        "        distances = self._calculate_distances(X)\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            test_distances = distances[i]\n",
        "\n",
        "            # Filter distances within the radius\n",
        "            within_radius_indices = np.where(test_distances <= self.radius)[0]\n",
        "\n",
        "            if len(within_radius_indices) == 0:\n",
        "                closest_idx = np.argmin(test_distances)\n",
        "                predicted_label = self.y_train[closest_idx]\n",
        "            else:\n",
        "                within_radius_labels = self.y_train[within_radius_indices]\n",
        "                vote_counts = Counter(within_radius_labels)\n",
        "                predicted_label = vote_counts.most_common(1)[0][0]\n",
        "\n",
        "            all_predictions.append(predicted_label)\n",
        "\n",
        "        return np.array(all_predictions)\n",
        "\n",
        "class BatchFixedWindowKNNClassifier(FixedWindowKNNClassifier):\n",
        "    \"\"\"\n",
        "    Fixed Window KNN Classifier with batch processing.\n",
        "    \"\"\"\n",
        "    def __init__(self, radius=1.0, distance_metric='euclidean', batch_size=1000):\n",
        "        super().__init__(radius, distance_metric)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def _predict_single_sample(self, test_distances):\n",
        "        within_radius_indices = np.where(test_distances <= self.radius)[0]\n",
        "\n",
        "        if len(within_radius_indices) == 0:\n",
        "            closest_idx = np.argmin(test_distances)\n",
        "            predicted_label = self.y_train[closest_idx]\n",
        "        else:\n",
        "            within_radius_labels = self.y_train[within_radius_indices]\n",
        "            vote_counts = Counter(within_radius_labels)\n",
        "            predicted_label = vote_counts.most_common(1)[0][0]\n",
        "\n",
        "        return predicted_label\n",
        "\n",
        "    def predict(self, X):\n",
        "        all_predictions = []\n",
        "\n",
        "        n_batches = (len(X) + self.batch_size - 1) // self.batch_size\n",
        "\n",
        "        batch_progress = tqdm(total=n_batches, desc=\"Progress\", position=0)\n",
        "\n",
        "        for i in range(n_batches):\n",
        "            start_idx = i * self.batch_size\n",
        "            end_idx = min((i + 1) * self.batch_size, len(X))\n",
        "            X_batch = X[start_idx:end_idx]\n",
        "\n",
        "            batch_progress.set_postfix_str(f\"Batch {i+1}/{n_batches} ({len(X_batch)} samples)\")\n",
        "\n",
        "            batch_distances = self._calculate_distances(X_batch)\n",
        "\n",
        "            batch_predictions = []\n",
        "            batch_neighbor_counts = []\n",
        "\n",
        "            for j in range(len(X_batch)):\n",
        "                test_distances = batch_distances[j]\n",
        "                predicted_label = self._predict_single_sample(test_distances)\n",
        "                batch_predictions.append(predicted_label)\n",
        "\n",
        "            batch_progress.update(1)\n",
        "\n",
        "            all_predictions.extend(batch_predictions)\n",
        "\n",
        "            del batch_distances, batch_predictions\n",
        "            gc.collect()\n",
        "\n",
        "        batch_progress.close()\n",
        "\n",
        "        return np.array(all_predictions)\n",
        "\n",
        "\n",
        "def find_best_radius(X_train, y_train, X_test, y_test, distance_metric, radius_values):\n",
        "\n",
        "    best_radius = radius_values[0]\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for radius in radius_values:\n",
        "        model = FixedWindowKNNClassifier(radius=radius, distance_metric=distance_metric)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_test_pred = model.predict(X_test)\n",
        "        current_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "        if current_accuracy > best_accuracy:\n",
        "            best_radius = radius\n",
        "            best_accuracy = current_accuracy\n",
        "\n",
        "    return best_radius, best_accuracy\n",
        "\n",
        "def fetch_spambase_data():\n",
        "    \"\"\"\n",
        "    Fetch Spambase dataset from UCI repository\n",
        "    \"\"\"\n",
        "    spambase = fetch_ucirepo(id=94)\n",
        "\n",
        "    # Extract features and targets\n",
        "    X = spambase.data.features.values\n",
        "    y = spambase.data.targets.values.ravel()\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_data(X, y):\n",
        "    \"\"\"\n",
        "    Preprocess the data\n",
        "    \"\"\"\n",
        "    # Covert labels to 1/-1\n",
        "    y = np.where(y == 0, -1, 1)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def fetch_digit_dataset():\n",
        "    zip_url = \"https://www.khoury.northeastern.edu/home/vip/teach/MLcourse/data/mnist_haar_bingyu.zip\"\n",
        "    zip_filename = \"mnist_haar_bingyu.zip\"\n",
        "    extracted_folder = \"mnist_haar_bingyu\"\n",
        "    response = requests.get(zip_url)\n",
        "    with open(zip_filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "\n",
        "    train_images = np.loadtxt(os.path.join(extracted_folder, \"training_image.txt\"), delimiter=',')\n",
        "    train_labels = np.loadtxt(os.path.join(extracted_folder, \"training_label.txt\"), dtype=int, delimiter=',')\n",
        "    test_images = np.loadtxt(os.path.join(extracted_folder, \"testing_image.txt\"), delimiter=',')\n",
        "    test_labels = np.loadtxt(os.path.join(extracted_folder, \"testing_label.txt\"), dtype=int, delimiter=',')\n",
        "\n",
        "    return train_images, test_images, train_labels, test_labels\n",
        "\n",
        "def train_and_evaluate_spambase_fixed_window(X_train, X_test, y_train, y_test):\n",
        "    print(\"=\"*50)\n",
        "    print(\"Spambase Evaluation\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    best_radius, best_accuracy = find_best_radius(X_train, y_train, X_test, y_test, 'euclidean', [0.01, 0.02, 0.03, 0.04, 0.5, 1, 1.5, 2.0, 2.5])\n",
        "\n",
        "    model = FixedWindowKNNClassifier(radius=best_radius, distance_metric='euclidean')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"\\nBest Radius: {best_radius}\")\n",
        "    print(f\"Train Accuracy: {train_accuracy:.2%}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
        "\n",
        "def train_and_evaluate_digits_fixed_window(X_train, X_test, y_train, y_test):\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Digit Evaluation\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    best_radius, best_accuracy = find_best_radius(X_train, y_train, X_test, y_test, distance_metric='cosine', radius_values=[0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.2, 0.25])\n",
        "\n",
        "    model = BatchFixedWindowKNNClassifier(radius=best_radius, distance_metric='cosine')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Best Radius: {best_radius}\")\n",
        "    print(f\"Train Accuracy: {train_accuracy:.2%}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y = fetch_spambase_data()\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
        "\n",
        "    train_and_evaluate_spambase_fixed_window(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = fetch_digit_dataset()\n",
        "\n",
        "    train_and_evaluate_digits_fixed_window(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eR4umtIIJXI",
        "outputId": "6ea86a55-9030-4626-d48f-631cd59d2827"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.7.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "==================================================\n",
            "Spambase Evaluation\n",
            "==================================================\n",
            "\n",
            "Best Radius: 0.5\n",
            "Train Accuracy: 99.57%\n",
            "Test Accuracy: 94.35%\n",
            "\n",
            "==================================================\n",
            "Digit Evaluation\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Progress: 100%|██████████| 60/60 [01:36<00:00,  1.60s/it, Batch 60/60 (1000 samples)]\n",
            "Progress: 100%|██████████| 10/10 [00:17<00:00,  1.71s/it, Batch 10/10 (1000 samples)]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Radius: 0.01\n",
            "Train Accuracy: 99.94%\n",
            "Test Accuracy: 94.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ucimlrepo\n",
        "\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "class KernelDensityBayesClassifier:\n",
        "    def __init__(self, bandwidth=1.0):\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.class_data_ = {}\n",
        "        self.class_counts_ = {}\n",
        "        self.class_priors_ = {}\n",
        "\n",
        "        self.classes = np.unique(y)\n",
        "        n_totals = len(y)\n",
        "\n",
        "        for class_label in self.classes:\n",
        "            class_mask = (y == class_label)\n",
        "            self.class_data_[class_label] = X[class_mask]\n",
        "            self.class_counts_[class_label] = np.sum(class_mask)\n",
        "            self.class_priors_[class_label] = self.class_counts_[class_label] / n_totals\n",
        "\n",
        "    def _estimate_class_density(self, X, class_label):\n",
        "        \"\"\"\n",
        "        Estimate probability density P(z|C) for specified class\n",
        "        Using Gaussian kernel: P(z|C) = (1/m_C) * Σ K((z - x_i) / h)\n",
        "        \"\"\"\n",
        "        X_class = self.class_data_[class_label]\n",
        "        m_c = self.class_counts_[class_label]\n",
        "        kernel_similarity = rbf_kernel(X, X_class, gamma=1.0 / (2 * self.bandwidth ** 2))\n",
        "        return (1 / m_c) * np.sum(kernel_similarity, axis=1)\n",
        "\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict class probabilities\n",
        "        Using Bayes' theorem: P(C|z) = P(C) * P(z|C) / P(z)\n",
        "        \"\"\"\n",
        "        n_samples = len(X)\n",
        "        n_classes = len(self.classes)\n",
        "        class_probabilities = np.zeros((n_samples, n_classes))\n",
        "\n",
        "        for i, class_label in enumerate(self.classes):\n",
        "            prior = self.class_priors_[class_label]\n",
        "            likelihood = self._estimate_class_density(X, class_label)\n",
        "            class_probabilities[:, i] = prior * likelihood\n",
        "\n",
        "\n",
        "        total_probabilities = np.sum(class_probabilities, axis=1, keepdims=True)\n",
        "        total_probabilities = np.where(total_probabilities == 0, 1e-10, total_probabilities)\n",
        "\n",
        "\n",
        "        return class_probabilities / total_probabilities\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict class labels\n",
        "        \"\"\"\n",
        "        class_probabilities = self.predict_proba(X)\n",
        "        predict_indices = np.argmax(class_probabilities, axis=1)\n",
        "        return self.classes[np.argmax(class_probabilities, axis=1)]\n",
        "\n",
        "def fetch_spambase_data():\n",
        "    \"\"\"\n",
        "    Fetch Spambase dataset from UCI repository\n",
        "    \"\"\"\n",
        "    spambase = fetch_ucirepo(id=94)\n",
        "    X = spambase.data.features.values\n",
        "    y = spambase.data.targets.values.ravel()\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def preprocess_data(X, y):\n",
        "    \"\"\"\n",
        "    Preprocess the data\n",
        "    \"\"\"\n",
        "    # Convert labels to 1/-1\n",
        "    y = np.where(y == 0, -1, 1)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardization\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def train_and_evaluate_spambase_kde(X_train, X_test, y_train, y_test):\n",
        "    print(\"=\"*50)\n",
        "    print(\"Spambase Evaluation\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    model = KernelDensityBayesClassifier(bandwidth=1.0)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Train Accuracy: {train_accuracy:.2%}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y = fetch_spambase_data()\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(X, y)\n",
        "\n",
        "    train_and_evaluate_spambase_kde(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnk182Ysaz2O",
        "outputId": "3316880d-d991-4e0a-e7ec-8ec489883da1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.7.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "==================================================\n",
            "Spambase Evaluation\n",
            "==================================================\n",
            "Train Accuracy: 96.39%\n",
            "Test Accuracy: 90.45%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/sqRaFYNq6B93+d9WMg+e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}