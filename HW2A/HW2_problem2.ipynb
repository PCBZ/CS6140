{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjDOZP6M61hy",
        "outputId": "42fcdb68-f1c5-46ee-995d-a368db300814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Loaded 1000 samples with 4 features\n",
            "\n",
            "Training perceptron...\n",
            "\n",
            "Evaluating result...\n",
            "============================================================\n",
            "PERCEPTRON LEARNING RESULTS\n",
            "============================================================\n",
            "\n",
            "1. CONVERGENCE INFORMATION:\n",
            "   - Total iterations until convergence: 8\n",
            "\n",
            "2. MISTAKES PER ITERATION:\n",
            "   - Iteration 1, 136 mistakes\n",
            "   - Iteration 2, 68 mistakes\n",
            "   - Iteration 3, 50 mistakes\n",
            "   - Iteration 4, 22 mistakes\n",
            "   - Iteration 5, 21 mistakes\n",
            "   - Iteration 6, 34 mistakes\n",
            "   - Iteration 7, 25 mistakes\n",
            "   - Iteration 8, 0 mistakes\n",
            "\n",
            "3. CLASSIFIER WEIGHTS (INCLUDING OFFSET):\n",
            "[-2.8         0.50574652  1.1414341   1.70446291  2.26512145]\n",
            "\n",
            "4. NORMALIZED WITH THRESHOLD:\n",
            "[0.18062376 0.40765504 0.60873676 0.80897195]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    A simple implementation of the perceptron algorithm.\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate = 0.01, epochs = 100):\n",
        "        \"\"\"\n",
        "        Initialize the perceptron with a learning rate and number of epochs.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.iterations = 0\n",
        "        self.mistakes_per_epoch = []\n",
        "        self.total_mistakes = 0\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the perceptron to the training data.\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : numpy array\n",
        "            Features\n",
        "        y : numpy array\n",
        "            Targets\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Training\n",
        "        for epoch in range(self.epochs):\n",
        "            errors = 0\n",
        "            mistake_this_epoch = 0\n",
        "            for i in range(n_samples):\n",
        "                # Calculate linear output\n",
        "                linear_output = X[i] @ self.weights + self.bias\n",
        "\n",
        "                # Calculate prediction\n",
        "                y_pred = np.where(linear_output >= 0, 1, -1)\n",
        "\n",
        "                # Calculate error\n",
        "                error = y[i] - y_pred\n",
        "\n",
        "                # Update weights and bias\n",
        "                if y[i] != y_pred:\n",
        "                    self.weights += self.learning_rate * error * X[i]\n",
        "                    self.bias += self.learning_rate * error\n",
        "                    errors += 1\n",
        "                    mistake_this_epoch += 1\n",
        "\n",
        "            self.iterations += 1\n",
        "            self.mistakes_per_epoch.append(mistake_this_epoch)\n",
        "            self.total_mistakes += mistake_this_epoch\n",
        "\n",
        "            # if converge, stop\n",
        "            if errors == 0:\n",
        "                break\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the target for a given set of features.\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : numpy array\n",
        "            Features\n",
        "        Returns:\n",
        "        --------\n",
        "        numpy array\n",
        "            Predictions\n",
        "        \"\"\"\n",
        "        linear_output = X @ self.weights + self.bias\n",
        "        return np.where(linear_output >= 0, 1, -1)\n",
        "\n",
        "    def evaluate_result(self):\n",
        "        \"\"\"\n",
        "        Evaluate the result of the perceptron.\n",
        "        \"\"\"\n",
        "        print(\"=\"*60)\n",
        "        print(\"PERCEPTRON LEARNING RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(f\"\\n1. CONVERGENCE INFORMATION:\")\n",
        "        print(f\"   - Total iterations until convergence: {self.iterations}\")\n",
        "\n",
        "        print(f\"\\n2. MISTAKES PER ITERATION:\")\n",
        "        for i, mistakes in enumerate(self.mistakes_per_epoch):\n",
        "            print(f\"   - Iteration {i+1}, {mistakes} mistakes\")\n",
        "\n",
        "        print(f\"\\n3. CLASSIFIER WEIGHTS (INCLUDING OFFSET):\")\n",
        "        print(f\"{np.concatenate([[self.bias], self.weights])}\")\n",
        "\n",
        "        print(\"\\n4. NORMALIZED WITH THRESHOLD:\")\n",
        "        if self.bias != 0:\n",
        "            normalized_weights = self.weights / -self.bias\n",
        "            print(f\"{normalized_weights}\")\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load the perceptron data from a URL.\n",
        "    \"\"\"\n",
        "    data_url = \"https://www.khoury.northeastern.edu/home/vip/teach/MLcourse/data/perceptronData.txt\"\n",
        "\n",
        "    column_names = [f'feature_{i+1}' for i in range(4)] + ['label']\n",
        "    data = pd.read_csv(data_url, header=None, sep='\\t', names=column_names)\n",
        "\n",
        "    X, y = data.iloc[:, :-1].values, data.iloc[:, -1].values\n",
        "    return X, y\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the perceptron algorithm.\n",
        "    \"\"\"\n",
        "    print(\"Loading data...\")\n",
        "    X, y = load_data()\n",
        "    print(f\"Loaded {len(X)} samples with {X.shape[1]} features\")\n",
        "\n",
        "    # Create and train perceptron\n",
        "    print(\"\\nTraining perceptron...\")\n",
        "    perceptron = Perceptron(learning_rate = 0.1, epochs = 1000)\n",
        "    perceptron.fit(X, y)\n",
        "\n",
        "    # Evaluate result\n",
        "    print(\"\\nEvaluating result...\")\n",
        "    perceptron.evaluate_result()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}