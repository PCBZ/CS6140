{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5BjHT9eO52QtzzvJCc9fs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PCBZ/CS6140/blob/main/HW4/HW4_Problem3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr62ZkAfdN1d",
        "outputId": "3605835d-5993-4833-ea66-18637335297f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy per class:\n",
            "------------------------------------------------------------\n",
            "Class 0 (religion       ): 86.16%\n",
            "Class 1 (computer       ): 95.08%\n",
            "Class 2 (forsale        ): 69.74%\n",
            "Class 3 (autos          ): 80.23%\n",
            "Class 4 (sports         ): 89.45%\n",
            "Class 5 (med            ): 59.09%\n",
            "Class 6 (space          ): 79.19%\n",
            "Class 7 (politics       ): 82.76%\n",
            "------------------------------------------------------------\n",
            "Overall Accuracy: 86.02%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy.sparse import csr_matrix\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "def load_8newsgroup_data():\n",
        "    \"\"\"\n",
        "    Simplified 8newsgroup dataset loader\n",
        "    \"\"\"\n",
        "    import urllib.request\n",
        "    import zipfile\n",
        "    import tempfile\n",
        "    import re\n",
        "\n",
        "    # Download and extract to temporary directory\n",
        "    url = 'https://www.khoury.northeastern.edu/home/vip/teach/MLcourse/data/8newsgroup.zip'\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        # Download\n",
        "        zip_path = os.path.join(temp_dir, '8newsgroup.zip')\n",
        "        urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "        # Extract\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(temp_dir)\n",
        "\n",
        "        # Try to read category mappings from train.trec/data_settings.txt\n",
        "        categories = {}\n",
        "        data_settings_files = []\n",
        "\n",
        "        # Look for data_settings.txt in train.trec and test.trec directories\n",
        "        for root, dirs, files in os.walk(temp_dir):\n",
        "            if 'data_settings.txt' in files and ('train.trec' in root or 'test.trec' in root):\n",
        "                data_settings_files.append(os.path.join(root, 'data_settings.txt'))\n",
        "\n",
        "        if data_settings_files:\n",
        "            # Use the first found file (preferably from train.trec)\n",
        "            setting_file = data_settings_files[0]\n",
        "\n",
        "            with open(setting_file, 'r') as f:\n",
        "                for line in f:\n",
        "                    # Parse format: intId=8496,extId=8496,intLabel=6,extLabel=space\n",
        "                    match = re.search(r'intLabel=(\\d+),extLabel=(\\w+)', line)\n",
        "                    if match:\n",
        "                        label_id = int(match.group(1))\n",
        "                        label_name = match.group(2)\n",
        "                        categories[label_id] = label_name\n",
        "\n",
        "\n",
        "        category_names = [categories[i] for i in sorted(categories.keys())]\n",
        "\n",
        "        # Load data function\n",
        "        def load_file(file_path):\n",
        "            \"\"\"Load sparse data in TREC format\"\"\"\n",
        "            labels, rows, cols, values = [], [], [], []\n",
        "\n",
        "            with open(file_path, 'r') as f:\n",
        "                for i, line in enumerate(f):\n",
        "                    parts = line.strip().split()\n",
        "                    if parts:\n",
        "                        labels.append(int(parts[0]))\n",
        "                        for feat in parts[1:]:\n",
        "                            if ':' in feat:\n",
        "                                idx, val = feat.split(':')\n",
        "                                rows.append(i)\n",
        "                                cols.append(int(idx))\n",
        "                                values.append(float(val))\n",
        "\n",
        "            return labels, (values, (rows, cols))\n",
        "\n",
        "        # Find data files\n",
        "        train_file = test_file = None\n",
        "        for root, dirs, files in os.walk(temp_dir):\n",
        "            if 'feature_matrix.txt' in files:\n",
        "                if 'train' in root:\n",
        "                    train_file = os.path.join(root, 'feature_matrix.txt')\n",
        "                elif 'test' in root:\n",
        "                    test_file = os.path.join(root, 'feature_matrix.txt')\n",
        "\n",
        "        # Load train and test data\n",
        "        y_train, train_data = load_file(train_file)\n",
        "        y_test, test_data = load_file(test_file)\n",
        "\n",
        "        # Determine number of features from the data\n",
        "        # Find the maximum feature index in both train and test data\n",
        "        train_max_feature = max(train_data[1][1]) if train_data[1][1] else 0\n",
        "        test_max_feature = max(test_data[1][1]) if test_data[1][1] else 0\n",
        "        n_features = max(train_max_feature, test_max_feature) + 1  # +1 because indices start at 0\n",
        "\n",
        "        # Convert to sparse matrices\n",
        "        X_train = csr_matrix(train_data, shape=(len(y_train), n_features))\n",
        "        X_test = csr_matrix(test_data, shape=(len(y_test), n_features))\n",
        "\n",
        "        return X_train, np.array(y_train), X_test, np.array(y_test), category_names\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    X_train, y_train, X_test, y_test, categories = load_8newsgroup_data()\n",
        "\n",
        "    # Using strong L1 regularization\n",
        "    l1_model = LogisticRegression(penalty='l1', solver='saga', C=0.15, max_iter=2000, random_state=42, tol=0.001)\n",
        "    l1_model.fit(X_train, y_train)\n",
        "\n",
        "    # Get top 200 features\n",
        "    top_200_indices = np.argsort(np.sum(np.abs(l1_model.coef_), axis=0))[-200:]\n",
        "\n",
        "    X_train_selected = X_train[:, top_200_indices]\n",
        "    X_test_selected = X_test[:, top_200_indices]\n",
        "\n",
        "    l2_model = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, max_iter=1000, random_state=42, tol=0.0001)\n",
        "    l2_model.fit(X_train_selected, y_train)\n",
        "\n",
        "    y_pred = l2_model.predict(X_test_selected)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "    # Show per-class accuracy\n",
        "    print(\"\\nAccuracy per class:\")\n",
        "    print(\"-\"*60)\n",
        "    for i, (category, accuracy) in enumerate(zip(categories, class_accuracies)):\n",
        "        correct = cm[i, i]\n",
        "        total = cm[i].sum()\n",
        "        print(f\"Class {i} ({category:<15}): {accuracy:6.2%}\")\n",
        "\n",
        "    # Overall accuracy\n",
        "    overall_accuracy = l2_model.score(X_test_selected, y_test)\n",
        "    print(\"-\"*60)\n",
        "    print(f\"Overall Accuracy: {overall_accuracy:.2%}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}