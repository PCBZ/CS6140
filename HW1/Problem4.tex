\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{parskip}

\title{Problem 4}
\author{}
\date{}

\begin{document}
\maketitle
\thispagestyle{empty}

Consider a classification problem with:
\begin{itemize}
    \item A target variable \( Y \) with \( K \) classes.
    \item A binary feature \( X \in \{0, 1\} \) used for splitting.
\end{itemize}

We define:
\begin{itemize}
    \item \( H(Y) \): Entropy of the target variable \( Y \).
    \item \( H(Y|X) \): Conditional entropy of \( Y \) given \( X \).
    \item \( I(X; Y) \): Mutual information between \( X \) and \( Y \), which represents the \textbf{information gain} from splitting on \( X \).
\end{itemize}

The mutual information is defined as:
\[
I(X; Y) = H(Y) - H(Y|X)
\]

From information theory, mutual information is symmetric:
\[
I(X; Y) = I(Y; X) = H(X) - H(X|Y)
\]

Since \( X \) is binary, we know:
\[
H(X) \leq 1
\]
and the conditional entropy \( H(X|Y) \) is non-negative:
\[
H(X|Y) \geq 0
\]

Therefore:
\[
I(X; Y) = H(X) - H(X|Y) \leq H(X) \leq 1
\]

Thus:
\[
H(Y) - H(Y|X) = I(X; Y) \leq 1
\]

\end{document}