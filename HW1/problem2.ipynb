{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oRIolQU_GnX",
        "outputId": "56af8f8b-d078-4cd0-9c55-3a5cdd5d065a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "LINEAR REGRESSION ON HOUSING DATASET\n",
            "======================================================================\n",
            "\n",
            "Loading Housing dataset from predefined train/test files...\n",
            "Dataset loaded successfully:\n",
            "  Training set: 433 samples, 13 features\n",
            "  Testing set: 74 samples, 13 features\n",
            "   Training MSE: 22.0813, R²: 0.7546\n",
            "   Testing MSE: 22.6383, R²: 0.4577\n",
            "\n",
            "Intercept: 27.7723\n",
            "\n",
            "Feature coefficients:\n",
            "   CRIM: -8.9982\n",
            "   ZN: 4.5894\n",
            "   INDUS: -0.0688\n",
            "   CHAS: 3.0720\n",
            "   NOX: -8.2510\n",
            "   RM: 19.3690\n",
            "   AGE: 0.6951\n",
            "   DIS: -17.5841\n",
            "   RAD: 8.5933\n",
            "   TAX: -7.5473\n",
            "   PTRATIO: -8.8079\n",
            "   B: 3.8441\n",
            "   LSTAT: -20.6554\n",
            "\n",
            "\n",
            "\n",
            "LINEAR REGRESSION ON SPAMBASE DATASET\n",
            "======================================================================\n",
            "\n",
            "Loading spambase dataset from predefined train/test files...\n",
            "Dataset loaded successfully:\n",
            "  Features: 4601 samples, 57 features\n",
            "   Threshold: 0.1, Accuracy: 0.5939\n",
            "   Threshold: 0.2, Accuracy: 0.7231\n",
            "   Threshold: 0.3, Accuracy: 0.8534\n",
            "   Threshold: 0.4, Accuracy: 0.9077\n",
            "   Threshold: 0.5, Accuracy: 0.8817\n",
            "   Threshold: 0.6, Accuracy: 0.8371\n",
            "   Threshold: 0.7, Accuracy: 0.7818\n",
            "   Threshold: 0.8, Accuracy: 0.7318\n",
            "   Threshold: 0.9, Accuracy: 0.6982\n",
            "   Best threshold: 0.4, Best accuracy: 0.9077\n",
            "   Threshold: 0.1, Accuracy: 0.5957\n",
            "   Threshold: 0.2, Accuracy: 0.7130\n",
            "   Threshold: 0.3, Accuracy: 0.8424\n",
            "   Threshold: 0.4, Accuracy: 0.9000\n",
            "   Threshold: 0.5, Accuracy: 0.8924\n",
            "   Threshold: 0.6, Accuracy: 0.8478\n",
            "   Threshold: 0.7, Accuracy: 0.8043\n",
            "   Threshold: 0.8, Accuracy: 0.7457\n",
            "   Threshold: 0.9, Accuracy: 0.7120\n",
            "   Best threshold: 0.4, Best accuracy: 0.9000\n",
            "   Threshold: 0.1, Accuracy: 0.5652\n",
            "   Threshold: 0.2, Accuracy: 0.6902\n",
            "   Threshold: 0.3, Accuracy: 0.8543\n",
            "   Threshold: 0.4, Accuracy: 0.9098\n",
            "   Threshold: 0.5, Accuracy: 0.8804\n",
            "   Threshold: 0.6, Accuracy: 0.8337\n",
            "   Threshold: 0.7, Accuracy: 0.7891\n",
            "   Threshold: 0.8, Accuracy: 0.7598\n",
            "   Threshold: 0.9, Accuracy: 0.7196\n",
            "   Best threshold: 0.4, Best accuracy: 0.9098\n",
            "   Threshold: 0.1, Accuracy: 0.5630\n",
            "   Threshold: 0.2, Accuracy: 0.6902\n",
            "   Threshold: 0.3, Accuracy: 0.8587\n",
            "   Threshold: 0.4, Accuracy: 0.9152\n",
            "   Threshold: 0.5, Accuracy: 0.8935\n",
            "   Threshold: 0.6, Accuracy: 0.8500\n",
            "   Threshold: 0.7, Accuracy: 0.8152\n",
            "   Threshold: 0.8, Accuracy: 0.7522\n",
            "   Threshold: 0.9, Accuracy: 0.7109\n",
            "   Best threshold: 0.4, Best accuracy: 0.9152\n",
            "   Threshold: 0.1, Accuracy: 0.6087\n",
            "   Threshold: 0.2, Accuracy: 0.7685\n",
            "   Threshold: 0.3, Accuracy: 0.8696\n",
            "   Threshold: 0.4, Accuracy: 0.9109\n",
            "   Threshold: 0.5, Accuracy: 0.8880\n",
            "   Threshold: 0.6, Accuracy: 0.8413\n",
            "   Threshold: 0.7, Accuracy: 0.8120\n",
            "   Threshold: 0.8, Accuracy: 0.7652\n",
            "   Threshold: 0.9, Accuracy: 0.7261\n",
            "   Best threshold: 0.4, Best accuracy: 0.9109\n",
            "[0.9097826086956522, 0.9127954360228199, 0.9089921217060581, 0.910893778864439, 0.9136104319478403]\n",
            "\n",
            "======================================================================\n",
            "CROSS-VALIDATION RESULTS (5 FOLDS)\n",
            "======================================================================\n",
            "\n",
            "Average Performance Metrics:\n",
            "  Training Accuracy: 0.9112 ± 0.0018\n",
            "  Validation Accuracy: 0.9087 ± 0.0050\n"
          ]
        }
      ],
      "source": [
        "%pip install ucimlrepo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "# 1. LINEAR REGRESSION IMPLEMENTATION USING NORMAL EQUATIONS\n",
        "#-----------------------------------------------------------------\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self, fit_intercept=True):\n",
        "        \"\"\"\n",
        "        Linear Regression using normal equations\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        fit_intercept : bool, default=True\n",
        "            Whether to calculate the intercept for this model.\n",
        "            If set to False, no intercept will be used in calculations.\n",
        "        \"\"\"\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.coefficients = None\n",
        "        self.intercept = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the model using the normal equations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : training array, shape = [n_samples, n_features]\n",
        "        y : target values, shape = [n_samples]\n",
        "        \"\"\"\n",
        "        X_copy = X.copy()\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            X_copy = np.column_stack((np.ones(X.shape[0]), X_copy))\n",
        "\n",
        "        # calculate X^TX -1\n",
        "        XTX = np.dot(X_copy.T, X_copy)\n",
        "        XTX_inv = np.linalg.inv(XTX)\n",
        "\n",
        "        # calculate X^Ty\n",
        "        XTy = np.dot(X_copy.T, y)\n",
        "\n",
        "        # calculate coefficients\n",
        "        theta = np.dot(XTX_inv, XTy)\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            self.intercept = theta[0]\n",
        "            self.coefficients = theta[1:]\n",
        "        else:\n",
        "            self.intercept = 0\n",
        "            self.coefficients = theta\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict using the linear model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            Samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y : array of shape = [n_samples]\n",
        "            Returns predicted values.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            return self.intercept + np.dot(X, self.coefficients)\n",
        "        else:\n",
        "            return np.dot(X, self.coefficients)\n",
        "\n",
        "    def predict_class(self, X, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Predict class labels for samples in X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            Samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y : array of shape = [n_samples]\n",
        "            predict class labels. (0 or 1)\n",
        "        \"\"\"\n",
        "        y_predict_continous = self.predict(X)\n",
        "        return (y_predict_continous >= threshold).astype(int)\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "# 2. LOAD HOUSING DATASET AND SPAMBASE DATASET\n",
        "#-----------------------------------------------------------------\n",
        "\n",
        "def fetch_housing_data():\n",
        "    \"\"\"\n",
        "    Fetch Housing dataset from predefined training and testing files\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    X_train : numpy array\n",
        "        Training features\n",
        "    y_train : numpy array\n",
        "        Training targets\n",
        "    X_test : numpy array\n",
        "        Testing features\n",
        "    y_test : numpy array\n",
        "        Testing targets\n",
        "    feature_names : list\n",
        "        List of feature names\n",
        "    \"\"\"\n",
        "    # URLs for training and testing data\n",
        "    train_url = \"https://www.khoury.northeastern.edu/home/vip/teach/MLcourse/data/housing_train.txt\"\n",
        "    test_url = \"https://www.khoury.northeastern.edu/home/vip/teach/MLcourse/data/housing_test.txt\"\n",
        "\n",
        "    # Feature names\n",
        "    feature_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS',\n",
        "                    'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
        "\n",
        "    # Load training data\n",
        "    train_response = requests.get(train_url)\n",
        "    train_response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "    train_data = pd.read_csv(StringIO(train_response.text), sep=\"\\s+\", header=None)\n",
        "    train_data.columns = feature_names\n",
        "\n",
        "    # Load testing data\n",
        "    test_response = requests.get(test_url)\n",
        "    test_response.raise_for_status()\n",
        "    test_data = pd.read_csv(StringIO(test_response.text), sep=\"\\s+\", header=None)\n",
        "    test_data.columns = feature_names\n",
        "\n",
        "    # Extract features and targets\n",
        "    X_train = train_data.iloc[:, :-1].values\n",
        "    y_train = train_data.iloc[:, -1].values\n",
        "\n",
        "    X_test = test_data.iloc[:, :-1].values\n",
        "    y_test = test_data.iloc[:, -1].values\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, feature_names\n",
        "\n",
        "def fetch_spambase_data():\n",
        "    \"\"\"\n",
        "    Fetch Spambase dataset from UCI repository\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    X : numpy array\n",
        "        Features\n",
        "    y : numpy array\n",
        "        Targets\n",
        "    \"\"\"\n",
        "    spambase = fetch_ucirepo(id=94)\n",
        "\n",
        "    # Extract features and targets\n",
        "    X = spambase.data.features.values\n",
        "    y = spambase.data.targets.values.ravel()\n",
        "\n",
        "    return X, y\n",
        "\n",
        "#-----------------------------------------------------------------\n",
        "# 3. MAIN FUNCTION: HOUSING DATASET ANALYSIS\n",
        "#-----------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    print(\"LINEAR REGRESSION ON HOUSING DATASET\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nLoading Housing dataset from predefined train/test files...\")\n",
        "\n",
        "    # Load the Housing dataset\n",
        "    X_train, y_train, X_test, y_test, feature_names = fetch_housing_data()\n",
        "\n",
        "    print(f\"Dataset loaded successfully:\")\n",
        "    print(f\"  Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
        "    print(f\"  Testing set: {X_test.shape[0]} samples, {X_test.shape[1]} features\")\n",
        "\n",
        "    # Normalize the data\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_norm = scaler.fit_transform(X_train)\n",
        "    X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "    # Linear Regression Training\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_norm, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_train_pred = model.predict(X_train_norm)\n",
        "    y_test_pred = model.predict(X_test_norm)\n",
        "\n",
        "    # Calculate MSE & R2\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"   Training MSE: {train_mse:.4f}, R²: {train_r2:.4f}\")\n",
        "    print(f\"   Testing MSE: {test_mse:.4f}, R²: {test_r2:.4f}\")\n",
        "\n",
        "    # Print model coefficients\n",
        "    print(f\"\\nIntercept: {model.intercept:.4f}\")\n",
        "    print(\"\\nFeature coefficients:\")\n",
        "    for i, feature in enumerate(feature_names[:-1]):\n",
        "        print(f\"   {feature}: {model.coefficients[i]:.4f}\")\n",
        "\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"LINEAR REGRESSION ON SPAMBASE DATASET\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nLoading spambase dataset from predefined train/test files...\")\n",
        "\n",
        "    # Load spambase dataset\n",
        "    X, y = fetch_spambase_data()\n",
        "\n",
        "    print(f\"Dataset loaded successfully:\")\n",
        "    print(f\"  Features: {X.shape[0]} samples, {X.shape[1]} features\")\n",
        "\n",
        "    # k-fold cross validation\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "\n",
        "    fold_train_accuracies = []\n",
        "    fold_test_accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        # Split data\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Apply normalization\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train_norm = scaler.fit_transform(X_train)\n",
        "        X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "        # Training with Linear Regression Model\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train_norm, y_train)\n",
        "\n",
        "        best_threshold, best_accuracy = None, 0\n",
        "\n",
        "        # Find an optimal threshold\n",
        "        for threshold in thresholds:\n",
        "            # Predict\n",
        "            y_pred_class = model.predict_class(X_test_norm, threshold=threshold)\n",
        "            # Calculate accuray\n",
        "            accuracy = accuracy_score(y_test, y_pred_class)\n",
        "\n",
        "            print(f\"   Threshold: {threshold}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "            # Update best\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_threshold = threshold\n",
        "\n",
        "        print(f\"   Best threshold: {best_threshold}, Best accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "        y_train_pred = model.predict_class(X_train_norm, threshold=best_threshold)\n",
        "        y_test_pred = model.predict_class(X_test_norm, threshold=best_threshold)\n",
        "\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "        fold_train_accuracies.append(train_accuracy)\n",
        "        fold_test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Calculate accuracy average and standard deviations\n",
        "    print(fold_train_accuracies)\n",
        "    avg_train_accuracy = np.mean(fold_train_accuracies)\n",
        "    avg_test_accuracy = np.mean(fold_test_accuracies)\n",
        "    std_train_accuracy = np.std(fold_train_accuracies)\n",
        "    std_test_accuracy = np.std(fold_test_accuracies)\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"CROSS-VALIDATION RESULTS (5 FOLDS)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(\"\\nAverage Performance Metrics:\")\n",
        "    print(f\"  Training Accuracy: {avg_train_accuracy:.4f} ± {std_train_accuracy:.4f}\")\n",
        "    print(f\"  Validation Accuracy: {avg_test_accuracy:.4f} ± {std_test_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision(Regression) Tree vs. Linear Regression\n",
        "## Housing Data Comparison\n",
        "For housing data, regression tree shows the result of training MSE: 6.6557 and testing MSE: 32.3248, while linear regression shows the result of training MSE: 22.0813 and testing MSE: 22.6383.\n",
        "\n",
        "Linear Regregssion is clearly better on this dataset. Lower testing MSE means better predictive performance on new data.\n",
        "\n",
        "## Spambase Data Comparison\n",
        "For spambase data, decision tree shows the result of training accuracy: 96.60% and testing accuracy: 92.48%, while linear regression shows the result of training accuracy: 91.12% and testing accuracy: 90.87%.\n",
        "\n",
        "Both models demonstrate viable approaches to spam classification:\n",
        "The Decision Tree achieves higher absolute accuracy at the cost of some generalization capability, making it suitable for applications where correctly identifying as many spam emails as possible is the top priority. The Linear Regression offers exceptional consistency and stability, making it appropriate for scenarios where reliable, consistent performance is more important than maximizing raw accuracy."
      ],
      "metadata": {
        "id": "UX1nS-B9Htt5"
      }
    }
  ]
}